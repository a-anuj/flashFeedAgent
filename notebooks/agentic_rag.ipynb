{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0a85d835",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install google-generativeai\n",
    "import sys\n",
    "sys.setrecursionlimit(100000)\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6a41eb92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d766910b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import google.generativeai as genai\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "genai.configure(api_key=os.getenv(\"GOOGLE_API_KEY\"))\n",
    "\n",
    "model = genai.GenerativeModel(\"gemini-2.0-flash\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5b884aad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-05 18:26:15.035904: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-12-05 18:26:15.481125: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-12-05 18:26:17.744649: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from typing import List,TypedDict\n",
    "from langgraph.graph import StateGraph,END\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_core.documents import Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5237f993",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6884/2730872305.py:2: LangChainDeprecationWarning: The class `HuggingFaceBgeEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the `langchain-huggingface package and should be used instead. To use it run `pip install -U `langchain-huggingface` and import as `from `langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  emb = HuggingFaceBgeEmbeddings(model_name=\"thenlper/gte-small\")\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.embeddings import HuggingFaceBgeEmbeddings\n",
    "emb = HuggingFaceBgeEmbeddings(model_name=\"thenlper/gte-small\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9d7125e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 47 documents.\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import RecursiveUrlLoader\n",
    "from bs4 import BeautifulSoup as Soup\n",
    "\n",
    "# 1. Define the Root URL (Where to start)\n",
    "# Note: LangChain docs structure changes often. Ensure this is the active root.\n",
    "url = \"https://python.langchain.com/v0.2/docs/introduction/\" \n",
    "\n",
    "# 2. Configure the Loader\n",
    "loader = RecursiveUrlLoader(\n",
    "    url=url,\n",
    "    max_depth=2, # How deep to dig? (Root -> Child -> Grandchild)\n",
    "    # This specifically filters for the main content div to avoid navbars/footers\n",
    "    extractor=lambda x: Soup(x, \"html.parser\").text \n",
    ")\n",
    "\n",
    "# 3. Load the docs\n",
    "document = loader.load()\n",
    "\n",
    "print(f\"Loaded {len(document)} documents.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9ee40a5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='LangChain overview - Docs by LangChainSkip to main contentðŸš€ Share how you're building agents for a chance to win LangChain swag!Docs by LangChain home pageLangChain + LangGraphSearch...âŒ˜KAsk AIGitHubTry LangSmithTry LangSmithSearch...NavigationLangChain overviewLangChainLangGraphDeep AgentsIntegrationsLearnReferenceContributePythonOverviewGet startedInstallQuickstartPhilosophyCore componentsAgentsModelsMessagesToolsShort-term memoryStreamingStructured outputMiddlewareOverviewBuilt-in middlewareCustom middlewareAdvanced usageGuardrailsRuntimeContext engineeringModel Context Protocol (MCP)Human-in-the-loopMulti-agentRetrievalLong-term memoryAgent developmentLangSmith StudioTestAgent Chat UIDeploy with LangSmithDeploymentObservabilityOn this page Create an agent Core benefitsLangChain overviewCopy pageCopy pageLangChain v1.x is now available!For a complete list of changes and instructions on how to upgrade your code, see the release notes and migration guide.If you encounter any issues or have feedback, please open an issue so we can improve. To view v0.x documentation, go to the archived content and API reference.\n",
      "LangChain is the easiest way to start building agents and applications powered by LLMs. With under 10 lines of code, you can connect to OpenAI, Anthropic, Google, and more. LangChain provides a pre-built agent architecture and model integrations to help you get started quickly and seamlessly incorporate LLMs into your agents and applications.\n",
      "We recommend you use LangChain if you want to quickly build agents and autonomous applications. Use LangGraph, our low-level agent orchestration framework and runtime, when you have more advanced needs that require a combination of deterministic and agentic workflows, heavy customization, and carefully controlled latency.\n",
      "LangChain agents are built on top of LangGraph in order to provide durable execution, streaming, human-in-the-loop, persistence, and more. You do not need to know LangGraph for basic LangChain agent usage.\n",
      "â€‹ Create an agent\n",
      "Copy# pip install -qU langchain \"langchain[anthropic]\"\n",
      "from langchain.agents import create_agent\n",
      "\n",
      "def get_weather(city: str) -> str:\n",
      "    \"\"\"Get weather for a given city.\"\"\"\n",
      "    return f\"It's always sunny in {city}!\"\n",
      "\n",
      "agent = create_agent(\n",
      "    model=\"claude-sonnet-4-5-20250929\",\n",
      "    tools=[get_weather],\n",
      "    system_prompt=\"You are a helpful assistant\",\n",
      ")\n",
      "\n",
      "# Run the agent\n",
      "agent.invoke(\n",
      "    {\"messages\": [{\"role\": \"user\", \"content\": \"what is the weather in sf\"}]}\n",
      ")\n",
      "\n",
      "See the Installation instructions and Quickstart guide to get started building your own agents and applications with LangChain.\n",
      "â€‹ Core benefits\n",
      "Standard model interfaceDifferent providers have unique APIs for interacting with models, including the format of responses. LangChain standardizes how you interact with models so that you can seamlessly swap providers and avoid lock-in.Learn moreEasy to use, highly flexible agentLangChainâ€™s agent abstraction is designed to be easy to get started with, letting you build a simple agent in under 10 lines of code. But it also provides enough flexibility to allow you to do all the context engineering your heart desires.Learn moreBuilt on top of LangGraphLangChainâ€™s agents are built on top of LangGraph. This allows us to take advantage of LangGraphâ€™s durable execution, human-in-the-loop support, persistence, and more.Learn moreDebug with LangSmithGain deep visibility into complex agent behavior with visualization tools that trace execution paths, capture state transitions, and provide detailed runtime metrics.Learn more\n",
      "\n",
      "Edit the source of this page on GitHub.\n",
      "Connect these docs programmatically to Claude, VSCode, and more via MCP for real-time answers.Was this page helpful?YesNoInstall LangChainNextâŒ˜IDocs by LangChain home pagegithubxlinkedinyoutubeResourcesForumChangelogLangChain AcademyTrust CenterCompanyAboutCareersBloggithubxlinkedinyoutubePowered by Mintlify' metadata={'source': 'https://python.langchain.com/mintlify-assets/_next/static/css/5753c16396148c89.css?dpl=dpl_4iF8t32XTsP2ipT3dRmhQiZRJRBE', 'content_type': 'text/html; charset=utf-8', 'title': 'LangChain overview - Docs by LangChain', 'language': 'en'}\n"
     ]
    }
   ],
   "source": [
    "print(document[6])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9577de4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "Answer the following question based on the provided context. \n",
    "Also if any code snippet is available please provide it.\n",
    "Always answer for more then 100 words. \n",
    "<context>\n",
    "{context}\n",
    "</context>\n",
    "Question : {input}\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cd33f8f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b4526312",
   "metadata": {},
   "outputs": [],
   "source": [
    "splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=2000,\n",
    "    chunk_overlap=500\n",
    ")\n",
    "\n",
    "docs = splitter.split_documents(document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "62d9400a",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorstore = FAISS.from_documents(docs,embedding=emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "11e85a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vectorstore.as_retriever(k=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "40c780dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# context_docs = retriever.invoke(\"Give to me in detail about how to use agents in langchain\")\n",
    "# context = format_docs(context_docs)\n",
    "\n",
    "# final_prompt = prompt.format(context=context, input=\"Give to me in detail about how to use agents in langchain\")\n",
    "\n",
    "# response = model.generate_content(final_prompt)\n",
    "# print(response.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e21a885d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(context_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5340a241",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgentState(TypedDict):\n",
    "    question: str\n",
    "    documents: List[Document]\n",
    "    answer:str\n",
    "    needs_retrieval: bool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "906016a8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
